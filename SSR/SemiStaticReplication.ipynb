{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Binomial method"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from project_helpers import payoff"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T13:55:38.983399Z",
     "start_time": "2023-11-15T13:55:36.826727300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Defines a lower triangular matrix describing the stock dynamics\n",
    "def binomial_tree_stock(S, T, sigma, n):\n",
    "    dt = T / n\n",
    "    u = np.exp(sigma * np.sqrt(dt))\n",
    "    d = 1 / u\n",
    "\n",
    "    stock_tree = np.zeros((n + 1, n + 1))\n",
    "    stock_tree[0, 0] = S\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        stock_tree[i, i] = stock_tree[i - 1, i - 1] * u\n",
    "        for j in range(i, n + 1):\n",
    "            stock_tree[j, i - 1] = stock_tree[j - 1, i - 1] * d\n",
    "\n",
    "    return stock_tree\n",
    "\n",
    "\n",
    "# Returns a lower triangular matrix describing the Bermudan option price dynamics\n",
    "def binomial_bermudan_option_pricing(S, K, T, r, sigma, n, early_exercise_dates, style):\n",
    "    dt = T / n\n",
    "    u = np.exp(sigma * np.sqrt(dt))\n",
    "    d = 1 / u\n",
    "    p = (np.exp(r * dt) - d) / (u - d)\n",
    "\n",
    "    # Initialize option value matrix\n",
    "    option_values = np.zeros((n + 1, n + 1))\n",
    "\n",
    "    # Calculate the option values at expiration\n",
    "    for i in range(n + 1):\n",
    "        option_values[n][i] = payoff(S * (u ** i) * (d ** (n - i)), K, style)\n",
    "\n",
    "    # Calculate the option values at earlier exercise dates\n",
    "    for t in range(n - 1, -1, -1):\n",
    "        for i in range(t + 1):\n",
    "            hold_value = np.exp(-r * dt) * (p * option_values[t + 1][i+1] + (1 - p) * option_values[t + 1][i])\n",
    "            if round(t * dt,2) in early_exercise_dates:\n",
    "                option_values[t][i] = max(payoff(S * (u ** i) * (d ** (t - i)), K, style), hold_value)\n",
    "            else:\n",
    "                option_values[t][i] = hold_value\n",
    "\n",
    "    return option_values\n",
    "\n",
    "\n",
    "# Defines a lower triangular matrix describing the dynamics of an American option for the model\n",
    "def binomial_american_option_pricing(S, K, T, r, sigma, n, style):\n",
    "    dt = T / n\n",
    "    u = np.exp(sigma * np.sqrt(dt))\n",
    "    d = 1 / u\n",
    "    p = (np.exp(r * dt) - d) / (u - d)\n",
    "\n",
    "    # Initialize option value matrix\n",
    "    option_values = np.zeros((n + 1, n + 1))\n",
    "\n",
    "    # Calculate the option values at expiration\n",
    "    for i in range(n + 1):\n",
    "        option_values[n][i] = payoff(S * (u ** i) * (d ** (n - i)), K, style)\n",
    "\n",
    "    # Calculate the option values at earlier exercise dates\n",
    "    for t in range(n - 1, -1, -1):\n",
    "        for i in range(t + 1):\n",
    "            hold_value = np.exp(-r * dt) * (p * option_values[t + 1][i+1] + (1 - p) * option_values[t + 1][i])\n",
    "            option_values[t][i] = max(payoff(S * (u ** i) * (d ** (t - i)), K, style), hold_value)\n",
    "\n",
    "    return option_values\n",
    "\n",
    "\n",
    "# Defines a lower triangular matrix describing the Delta parameter in all possible states for any option in the binomial model\n",
    "def binomial_delta(option_values, sigma, T, n, S):\n",
    "    dt = T / n\n",
    "    u = np.exp(sigma * np.sqrt(dt))\n",
    "    d = 1 / u\n",
    "\n",
    "    delta=np.zeros((n, n))\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1):\n",
    "            delta[i][j] = (option_values[i + 1][j + 1] - option_values[i + 1][j]) / (S * (d ** (i - j)) * (u ** (j + 1)) - S * (d ** (i + 1 - j)) * (u ** j))\n",
    "\n",
    "    return delta\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T10:36:18.210372900Z",
     "start_time": "2023-11-15T10:36:18.163219500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "S0 = 40   # Initial stock price\n",
    "K = 40   # Strike price\n",
    "T = 1.0   # Time to maturity\n",
    "r = 0.06  # Risk-free interest rate\n",
    "sigma = 0.2  # Volatility\n",
    "n = 1000   # Number of time steps in the binomial tree\n",
    "M = 10   # Number of exercise dates\n",
    "early_exercise_dates = np.linspace(0, T, M + 1)  # List of early exercise dates\n",
    "\n",
    "# martingale measure parameters\n",
    "dt = T / n\n",
    "u = np.exp(sigma * np.sqrt(dt))  # Up movement \n",
    "d = 1 / u  # Down movement\n",
    "p = (np.exp(r * dt) - d) / (u - d)  # Probability of Up movement"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T10:36:18.218629100Z",
     "start_time": "2023-11-15T10:36:18.178174700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bermudan Option Price: 2.2777651246905153 American Option Price: 2.3192782619099632\n"
     ]
    }
   ],
   "source": [
    "bermudan_option_prices = binomial_bermudan_option_pricing(S0, K, T, r, sigma, n, early_exercise_dates, 'put')\n",
    "american_option_prices = binomial_american_option_pricing(S0, K, T, r, sigma, n, 'put')\n",
    "print(\"Bermudan Option Price:\", bermudan_option_prices[0][0], \"American Option Price:\", american_option_prices[0][0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T10:36:28.756533700Z",
     "start_time": "2023-11-15T10:36:18.194405900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Semi-Static Replication via Regress-Later Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T13:55:45.661114300Z",
     "start_time": "2023-11-15T13:55:38.985903200Z"
    }
   },
   "outputs": [],
   "source": [
    "from project_helpers import gen_paths, forward, bs_put, bs_call\n",
    "from project_network import SemiStaticNet, fitting, pre_training\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model implementation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T13:55:45.677269900Z",
     "start_time": "2023-11-15T13:55:45.669113300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute the continuation value Q for the N paths at time t_{m-1}\n",
    "def continuation_q(trained_weights, stock, delta_t): # normalizingC is normalizing constant from fitting t+1\n",
    "    \n",
    "    w_1 = trained_weights[0]  # first layer weights\n",
    "    b_1 = trained_weights[1]  # first layer biases\n",
    "    w_2 = trained_weights[2]  # second layer weights\n",
    "    b_2 = trained_weights[3][0]  # second layer bias\n",
    "    p = len(w_2)  # number of hidden nodes in the first hidden layer\n",
    "    cont = []  # continuation vector\n",
    "\n",
    "    for s_tm in stock:\n",
    "        sum_cond_exp = b_2\n",
    "        cond_exp = 0\n",
    "        for i in range(p):\n",
    "            w_i = w_1[0][i]\n",
    "            b_i = b_1[i] + w_1[0][i]\n",
    "            omega_i = w_2[i][0]\n",
    "\n",
    "            if w_i >= 0 and b_i >= 0:\n",
    "                cond_exp = w_i * forward(s_tm, r, delta_t) + b_i\n",
    "            elif w_i > 0 > b_i:\n",
    "                cond_exp = w_i * bs_call(s_tm, -b_i / w_i, delta_t, r, sigma)\n",
    "            elif w_i < 0 < b_i:\n",
    "                cond_exp = - w_i * bs_put(s_tm, -b_i / w_i, delta_t, r, sigma)\n",
    "            elif w_i <= 0 and b_i <= 0:\n",
    "                cond_exp = 0\n",
    "\n",
    "            sum_cond_exp += omega_i * cond_exp\n",
    "\n",
    "        # Discount by the risk-free rate\n",
    "        cont.append(sum_cond_exp * np.exp(- r * delta_t))\n",
    "\n",
    "    return cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T13:55:45.709905400Z",
     "start_time": "2023-11-15T13:55:45.689802400Z"
    }
   },
   "outputs": [],
   "source": [
    "def model(S0, K, mu, sigma, N, monitoring_dates, style, optimizer=tf.keras.optimizers.Adamax(learning_rate=0.001), model_weights=None):\n",
    "    \"\"\"\n",
    "    monitoring_dates: t0=0, ..., tM=T\n",
    "    \"\"\"\n",
    "    # generate sample paths of asset S\n",
    "    sample_pathsS = gen_paths(monitoring_dates, S0, mu, sigma, N)\n",
    "\n",
    "    # evaluate maturity time option values\n",
    "    M = len(monitoring_dates) - 1\n",
    "    option = np.zeros(sample_pathsS.shape)\n",
    "    option[:, M] = payoff(sample_pathsS[:, M], K, style)\n",
    "\n",
    "    # fit the model at T, store fitted weights to initialize next regression\n",
    "    betas = []  # store model weights\n",
    "    \n",
    "    # double pre-training because why not\n",
    "    first_pre_weights = pre_training(sample_pathsS[:, M], option[:, M], \n",
    "                                     tf.keras.optimizers.Adam(learning_rate=0.01), 500, 0.8,weights=model_weights)\n",
    "\n",
    "    second_pre_weights = pre_training(sample_pathsS[:, M], option[:, M],\n",
    "                                      tf.keras.optimizers.Adam(learning_rate=0.0005), 500, 0.8,weights=first_pre_weights)\n",
    "    \n",
    "    # now it gets serious\n",
    "    fitted_beta = fitting(sample_pathsS[:, M], option[:, M],\n",
    "                          weights=second_pre_weights, optimizer=optimizer)\n",
    "    betas.append(fitted_beta)\n",
    "\n",
    "    # Compute option value at T-1\n",
    "    h = payoff(sample_pathsS[:, M - 1], K, style)                           # value of exercising now\n",
    "    time_increments = np.diff(monitoring_dates)\n",
    "    q = continuation_q(fitted_beta, sample_pathsS[:, M - 1], time_increments[M - 1])   # continuation value\n",
    "    option[:, M - 1] = np.maximum(h, q)                     # take maximum of both values\n",
    "    \n",
    "    # compute option values by backward regression\n",
    "    for m in range(M - 1, 0, -1):\n",
    "\n",
    "        # fit new weights, initialise with previous weights\n",
    "        fitted_beta = fitting(sample_pathsS[:, m], option[:, m], weights=fitted_beta, optimizer=optimizer)\n",
    "\n",
    "        # compute estimated option value one time step earlier\n",
    "        h = payoff(sample_pathsS[:, m - 1], K, style)                       # value of exercising now\n",
    "        q = continuation_q(fitted_beta, sample_pathsS[:, m - 1], time_increments[m - 1])       # continuation value\n",
    "        option[:, m - 1] = np.maximum(h, q)                  # take maximum of both values\n",
    "\n",
    "        # append the model weights to the beta list\n",
    "        betas.append(fitted_beta)\n",
    "    \n",
    "    # visualize_fit(betas, option, sample_pathsS, optimizer)\n",
    "\n",
    "    return betas, option\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def visualize_fit(trained_weights, option_values, stock_values, optimizer):\n",
    "    dates = len(option_values[0])\n",
    "\n",
    "    # Lists to store data for plotting\n",
    "    actual_values_list = []\n",
    "    predicted_values_list = []\n",
    "    rlnn = SemiStaticNet(None, optimizer)\n",
    "    for i in range(dates - 1):\n",
    "        rlnn.initialize_parameters(trained_weights[i])\n",
    "        actual_values = option_values[:, dates - 1 - i]\n",
    "        predicted_values = np.array(rlnn.predict(stock_values[:, dates - 1 - i]))\n",
    "\n",
    "        actual_values_list.append(actual_values)\n",
    "        predicted_values_list.append(predicted_values)\n",
    "\n",
    "    # Create the plot outside the loop\n",
    "    plt.figure()\n",
    "    for i in range(dates - 1):\n",
    "        plt.plot(stock_values[:, dates - 1 - i], actual_values_list[i], label=f'Option value at {dates - i}-th monitoring date', color='b')\n",
    "        plt.plot(stock_values[:, dates - 1 - i], predicted_values_list[i], label=f'Regressed option value at {dates - i}-th monitoring date', color='r')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T13:55:45.709905400Z",
     "start_time": "2023-11-15T13:55:45.701634500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T13:55:45.726887800Z",
     "start_time": "2023-11-15T13:55:45.709905400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Simulation parameters initialization\n",
    "# The asset prices follow a Geometric Brownian Motion\n",
    "S = 40  # Initial price\n",
    "mu = 0.06  # Drift\n",
    "sigma = 0.2  # Volatility\n",
    "K = 40  # Strike price\n",
    "r = 0.06  # Risk-free rate\n",
    "T = 1  # Maturity\n",
    "M = 10  # Number of monitoring dates\n",
    "N = 10000  # Number of sample paths\n",
    "pf_style = 'put'  # Payoff type\n",
    "monitoring_dates = np.linspace(0, T, M + 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-11-15T13:55:45.717910800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 74.\n",
      "Epoch 80: early stopping\n"
     ]
    }
   ],
   "source": [
    "weights, option_value = model(S, K, mu, sigma, N, monitoring_dates, pf_style, optimizer=tf.keras.optimizers.Adamax(learning_rate=0.001))\n",
    "v_0 = option_value[:, 0][0]\n",
    "print(v_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T11:31:52.415715800Z",
     "start_time": "2023-11-15T10:48:31.221171400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 520.\n",
      "Epoch 526: early stopping\n",
      "Restoring model weights from the end of the best epoch: 181.\n",
      "Epoch 187: early stopping\n",
      "Restoring model weights from the end of the best epoch: 231.\n",
      "Epoch 237: early stopping\n",
      "Restoring model weights from the end of the best epoch: 271.\n",
      "Epoch 277: early stopping\n",
      "Restoring model weights from the end of the best epoch: 211.\n",
      "Epoch 217: early stopping\n",
      "Restoring model weights from the end of the best epoch: 214.\n",
      "Epoch 220: early stopping\n",
      "Restoring model weights from the end of the best epoch: 203.\n",
      "Epoch 209: early stopping\n",
      "Restoring model weights from the end of the best epoch: 298.\n",
      "Epoch 304: early stopping\n",
      "Restoring model weights from the end of the best epoch: 255.\n",
      "Epoch 261: early stopping\n",
      "Restoring model weights from the end of the best epoch: 356.\n",
      "Epoch 362: early stopping\n",
      "Restoring model weights from the end of the best epoch: 377.\n",
      "Epoch 383: early stopping\n",
      "Restoring model weights from the end of the best epoch: 245.\n",
      "Epoch 251: early stopping\n",
      "Restoring model weights from the end of the best epoch: 220.\n",
      "Epoch 226: early stopping\n",
      "Restoring model weights from the end of the best epoch: 227.\n",
      "Epoch 233: early stopping\n",
      "Restoring model weights from the end of the best epoch: 260.\n",
      "Epoch 266: early stopping\n",
      "Restoring model weights from the end of the best epoch: 192.\n",
      "Epoch 198: early stopping\n",
      "Restoring model weights from the end of the best epoch: 270.\n",
      "Epoch 276: early stopping\n",
      "Restoring model weights from the end of the best epoch: 261.\n",
      "Epoch 267: early stopping\n",
      "Restoring model weights from the end of the best epoch: 249.\n",
      "Epoch 255: early stopping\n",
      "Restoring model weights from the end of the best epoch: 290.\n",
      "Epoch 296: early stopping\n",
      "Restoring model weights from the end of the best epoch: 422.\n",
      "Epoch 428: early stopping\n",
      "Restoring model weights from the end of the best epoch: 244.\n",
      "Epoch 250: early stopping\n",
      "Restoring model weights from the end of the best epoch: 176.\n",
      "Epoch 182: early stopping\n",
      "Restoring model weights from the end of the best epoch: 237.\n",
      "Epoch 243: early stopping\n",
      "Restoring model weights from the end of the best epoch: 246.\n",
      "Epoch 252: early stopping\n",
      "Restoring model weights from the end of the best epoch: 166.\n",
      "Epoch 172: early stopping\n",
      "Restoring model weights from the end of the best epoch: 222.\n",
      "Epoch 228: early stopping\n",
      "Restoring model weights from the end of the best epoch: 232.\n",
      "Epoch 238: early stopping\n",
      "Restoring model weights from the end of the best epoch: 274.\n",
      "Epoch 280: early stopping\n",
      "Restoring model weights from the end of the best epoch: 299.\n",
      "Epoch 305: early stopping\n",
      "Restoring model weights from the end of the best epoch: 455.\n",
      "Epoch 461: early stopping\n",
      "Restoring model weights from the end of the best epoch: 250.\n",
      "Epoch 256: early stopping\n",
      "Restoring model weights from the end of the best epoch: 216.\n",
      "Epoch 222: early stopping\n",
      "Restoring model weights from the end of the best epoch: 261.\n",
      "Epoch 267: early stopping\n",
      "Restoring model weights from the end of the best epoch: 207.\n",
      "Epoch 213: early stopping\n",
      "Restoring model weights from the end of the best epoch: 267.\n",
      "Epoch 273: early stopping\n",
      "Restoring model weights from the end of the best epoch: 248.\n",
      "Epoch 254: early stopping\n",
      "Restoring model weights from the end of the best epoch: 215.\n",
      "Epoch 221: early stopping\n",
      "Restoring model weights from the end of the best epoch: 280.\n",
      "Epoch 286: early stopping\n",
      "Restoring model weights from the end of the best epoch: 218.\n",
      "Epoch 224: early stopping\n",
      "Restoring model weights from the end of the best epoch: 379.\n",
      "Epoch 385: early stopping\n",
      "Restoring model weights from the end of the best epoch: 142.\n",
      "Epoch 148: early stopping\n",
      "Restoring model weights from the end of the best epoch: 172.\n",
      "Epoch 178: early stopping\n",
      "Restoring model weights from the end of the best epoch: 270.\n",
      "Epoch 276: early stopping\n",
      "Restoring model weights from the end of the best epoch: 241.\n",
      "Epoch 247: early stopping\n",
      "Restoring model weights from the end of the best epoch: 243.\n",
      "Epoch 249: early stopping\n",
      "Restoring model weights from the end of the best epoch: 174.\n",
      "Epoch 180: early stopping\n",
      "Restoring model weights from the end of the best epoch: 243.\n",
      "Epoch 249: early stopping\n",
      "Restoring model weights from the end of the best epoch: 255.\n",
      "Epoch 261: early stopping\n",
      "Restoring model weights from the end of the best epoch: 315.\n",
      "Epoch 321: early stopping\n",
      "[1.3489166769958854, 1.3169183111105598, 1.3060740682439451, 1.293226025745175, 1.2840975981593117]\n"
     ]
    }
   ],
   "source": [
    "# perform a few runs that reuse each others weights\n",
    "v_0s = []\n",
    "parameters = weights[0]\n",
    "for i in range(5):\n",
    "    parameters, option_value = model(S, K, mu, sigma, N, monitoring_dates, pf_style, optimizer=tf.keras.optimizers.Adamax(learning_rate=0.001), model_weights=parameters)\n",
    "    parameters = parameters[0] \n",
    "    v_0= option_value[0, 0]\n",
    "    v_0s.append(v_0)\n",
    "print(v_0s)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Upper and lower bounds implementation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def upper_bound(trained_weights, stock_paths, strike, monitoring, style, optimizer):\n",
    "\n",
    "    sample_size = len(stock_paths[:, 0])\n",
    "    n_mon = len(monitoring)\n",
    "    differences = np.diff(monitoring)\n",
    "\n",
    "    b = np.exp(- r * np.cumsum(differences))\n",
    "    b = np.insert(b, 0, 1)\n",
    "\n",
    "    martingale = np.zeros((sample_size, n_mon))\n",
    "    for m in range(1, n_mon):\n",
    "        rlnn = SemiStaticNet(trained_weights[- m], optimizer)\n",
    "        q = continuation_q(trained_weights[- m], stock_paths[:, m - 1], differences[m - 1])\n",
    "        q_part = np.array(q) * b[m - 1]\n",
    "        g_part = rlnn.predict(stock_paths[:, m], verbose=0) * b[m]\n",
    "        \n",
    "        martingale[:, m] = g_part.reshape(-1) - q_part\n",
    "    \n",
    "    for i in range(sample_size):\n",
    "        martingale[i] = np.cumsum(martingale[i])\n",
    "\n",
    "    upr = np.zeros(sample_size)\n",
    "    for i in range(sample_size):\n",
    "        upr[i] = np.max(payoff(stock_paths[i], strike, style) * b - martingale[i])\n",
    "\n",
    "    upr = np.mean(upr)\n",
    "    \n",
    "    return upr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T12:07:19.482893Z",
     "start_time": "2023-11-15T12:07:19.467275500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def lower_bound(trained_weights, stock_paths, strike, monitoring, style):\n",
    "\n",
    "    sample_size, n_mon = len(stock_paths[:, 0]), len(monitoring)\n",
    "    differences = np.diff(monitoring)\n",
    "\n",
    "    # Given the weights of the fitted model, compute all the continuation values Q(S_{t_m}) and compare them with\n",
    "    # h(S_{t_m}) (for every time, for each sample path) and store in tau the exercising times, i.e. the minimum of\n",
    "    # the times when h(S_{t_m})>Q(S_{t_m})\n",
    "    tau = np.full(sample_size, n_mon)\n",
    "    h_of_s =  payoff(stock_paths[:, n_mon - 1], strike, style)\n",
    "\n",
    "    for m in range(n_mon - 1):\n",
    "        s = stock_paths[:, m]  # stock values at time m\n",
    "        h = payoff(s, strike, style)\n",
    "        # weights is going to be the outcome of model(), so the weights relative to the first time interval are the\n",
    "        # ones stored for last\n",
    "        q = continuation_q(trained_weights[n_mon - m - 2], s, differences[m])\n",
    "        exceed = np.logical_and(h > q, tau > m)\n",
    "        tau[exceed] = m\n",
    "        h_of_s[exceed] = h[exceed]\n",
    "\n",
    "    discounted_values = np.zeros(sample_size)\n",
    "    for j in range(sample_size):\n",
    "        indices = np.arange(tau[j]) - 1   # Indices up to the exercising time\n",
    "        discounted_values[j] = h_of_s[j] * np.exp(-r * np.sum(differences[indices]))\n",
    "\n",
    "    lowr = np.sum(discounted_values) / sample_size\n",
    "\n",
    "    return lowr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T11:52:18.264543400Z",
     "start_time": "2023-11-15T11:52:18.247243300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0614631418774674\n"
     ]
    }
   ],
   "source": [
    "stock = gen_paths(monitoring_dates, S, mu, sigma, 1000)\n",
    "\n",
    "low = lower_bound(weights, stock, K, monitoring_dates, 'put')\n",
    "print(low)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T12:07:56.193354800Z",
     "start_time": "2023-11-15T12:07:38.470818600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 504us/step\n",
      "32/32 [==============================] - 0s 804us/step\n",
      "32/32 [==============================] - 0s 527us/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 540us/step\n",
      "32/32 [==============================] - 0s 910us/step\n",
      "32/32 [==============================] - 0s 584us/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "2.4069137289120053\n"
     ]
    }
   ],
   "source": [
    "upr = upper_bound(weights, stock, K, monitoring_dates, 'put', optimizer=tf.keras.optimizers.Adamax(learning_rate=0.001))\n",
    "print(upr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T12:08:15.537701900Z",
     "start_time": "2023-11-15T12:07:56.193354800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "80005c33560ba7403099a7d4b5bf9c347c13b8937104dcd84e5e5384c0d058b2"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 ('randomName': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
